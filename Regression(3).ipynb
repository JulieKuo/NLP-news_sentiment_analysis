{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500 成分股名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓symbol時使用\n",
    "\n",
    "#Abbreviate company name\n",
    "sp_500 = pd.read_csv('WSJ S_P 500 成分股.csv')\n",
    "\n",
    "#[\"Co.\", \"Corp.\", \"Cos.\"]\n",
    "keyword = []\n",
    "for i in sp_500[\"Company\"]:\n",
    "    company = i.replace(\" Cl A\", \"\").replace(\" Cl B\", \"\").replace(\" Cl C\", \"\")\\\n",
    "                .replace(\" Series A\",\"\").replace(\" Series C\",\"\")\\\n",
    "                .replace(\" Inc.\", \"\")\\\n",
    "                .replace(\" PLC\", \"\")\\\n",
    "                .replace(\" Ltd.\", \"\")\\\n",
    "                .replace(\".com\", \"\")\\\n",
    "                .replace(\" N.A.\", \"\")\\\n",
    "                .replace(\" N.V.\", \"\")\n",
    "    keyword.append(company)\n",
    "sp_500[\"Company\"] = keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = []\n",
    "#path = 'C:\\\\Users\\\\Julie\\\\Documents\\\\Python\\\\news\\\\daily'\n",
    "path = 'C:\\\\Users\\\\Julie\\\\Documents\\\\Python\\\\news\\\\daily'\n",
    "for dirname in os.listdir(path):#資料夾裡的子資料夾\n",
    "    datapath.append(os.path.join(path, dirname))\n",
    "print(len(datapath))\n",
    "datapath[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datapath:\n",
    "    price = pd.read_csv(i)\n",
    "    price.columns = price.iloc[0]#重設column名\n",
    "    price.drop(0, inplace = True)#刪除column名原本的位置\n",
    "    price.reset_index(inplace=True, drop = True)#重設index\n",
    "    price.iloc[0,0] = datetime.strptime(price.iloc[0,0], \"%m/%d/%Y\").date()#格式錯誤，需改成日期\n",
    "    price.to_csv(i, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轉換日期格式，並排序\n",
    "for i in datapath:\n",
    "    df = pd.read_csv(i)\n",
    "    df.sort_values(by=['Date'], inplace = True, ignore_index = True)\n",
    "    df.to_csv(i, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Capital前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = []\n",
    "#path = 'C:\\\\Users\\\\Julie\\\\Documents\\\\Python\\\\news\\\\S&P500_marketcap'\n",
    "path = 'C:\\\\Users\\\\i7-870\\\\Documents\\\\Python\\\\news\\\\daily'\n",
    "for dirname in os.listdir(path):#資料夾裡的子資料夾\n",
    "    datapath.append(os.path.join(path, dirname))\n",
    "print(len(datapath))\n",
    "datapath[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(datapath)):\n",
    "    print(i, datapath[i])\n",
    "    data = pd.read_excel(datapath[i], usecols=[\"Date\", \"Market_Cap\"])\n",
    "    #修改日期格式\n",
    "    data[\"Date\"] = data[\"Date\"].apply(lambda X: X.replace(\"March\", \"Mar\").replace(\"April\", \"Apr\").replace(\"June\", \"Jun\").replace(\"July\", \"Jul\").replace(\"Sept\", \"Sep\").replace(\".\", \"\"))\n",
    "    data[\"Date\"] = data[\"Date\"].apply(lambda X: datetime.strptime(X, \"%b %d, %Y\").date())\n",
    "    data.sort_values(by=['Date'], inplace = True, ignore_index = True)#重新排序\n",
    "    \n",
    "    #修改市值格式\n",
    "    value = []\n",
    "    for j in data[\"Market_Cap\"]:\n",
    "        if \"M\" in j:\n",
    "            j = float(j.replace(\"M\", \"\"))\n",
    "            value.append(int(j * 1000000))\n",
    "        elif \"B\" in j:\n",
    "            j = float(j.replace(\"B\", \"\"))\n",
    "            value.append(int(j * 1000000000))\n",
    "        else:\n",
    "            j = float(j.replace(\"T\", \"\"))\n",
    "            value.append(int(j * 1000000000000))\n",
    "    data[\"Market_Cap\"] = value\n",
    "    \n",
    "    path = \"C:\\\\Users\\\\Julie\\\\Documents\\\\Python\\\\news\\\\S&P500_marketcap_new\\\\\"\n",
    "    data.to_csv(path + datapath[i].split(\"\\\\\")[-1].split(\".\")[0] + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Negative Ratio檔名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = []\n",
    "path = os.path.join(os.getcwd(), 'abbrev_news')\n",
    "for dirname in os.listdir(path):#資料夾裡的子資料夾\n",
    "    dir_path = os.listdir(os.path.join(path, dirname))\n",
    "    for filename in dir_path:\n",
    "        if \"_e.csv\" in filename:\n",
    "            datapath.append(os.path.join(path, dirname, filename))\n",
    "print(len(datapath))\n",
    "datapath[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concate X & Y to regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_df = pd.DataFrame()\n",
    "for i in range(len(datapath)):\n",
    "    '''開啟News Ratio的檔案'''\n",
    "    path1 = datapath[i]\n",
    "    data = pd.read_csv(path1)\n",
    "    \n",
    "    news_columns = [0] + list(range(19,29))#news需保留的部分\n",
    "    data = data.iloc[:, news_columns]\n",
    "    data.rename(columns = {'date': 'Date'}, inplace = True)#方便merge\n",
    "    \n",
    "    \n",
    "    '''抓出現在開的檔案的symbol'''\n",
    "    Symbol_index = np.where( (path1.split(\"\\\\\")[-1].split(\"_\")[0]) == (sp_500[\"Company\"]) )[0][0]\n",
    "                            #np.where(條件):滿足條件輸出公司名稱的index\n",
    "    symbol = sp_500[\"Symbol\"][Symbol_index]\n",
    "    print(i, symbol)\n",
    "    \n",
    "    \n",
    "    '''透過symbol開啟stock price的檔案'''\n",
    "    #path2 = 'C:\\\\Users\\\\Julie\\\\Documents\\\\Python\\\\news\\\\daily'\n",
    "    path2 = 'C:\\\\Users\\\\i7-870\\\\Documents\\\\Python\\\\news\\\\daily'\n",
    "    filepath = os.path.join(path2, symbol + \" 30-12-2003 - 10-05-2021 d.csv\")\n",
    "    price = pd.read_csv(filepath)\n",
    "    \n",
    "    \n",
    "    '''透過symbol開啟Market Capital的檔案'''\n",
    "    #path2 = 'C:\\\\Users\\\\Julie\\\\Documents\\\\Python\\\\news\\\\S&P500_marketcap'\n",
    "    path2 = 'C:\\\\Users\\\\i7-870\\\\Documents\\\\Python\\\\news\\\\S&P500_marketcap'\n",
    "    filepath = os.path.join(path2, symbol + \".csv\")\n",
    "    market_cap = pd.read_csv(filepath)\n",
    "    \n",
    "    \n",
    "    '''計算Return'''\n",
    "    price[\"Return\"] = np.log(price['Close'] / (price['Close'].shift(1)))\n",
    "    price[\"Adjusted_Return\"] = np.log10(price['Adj Close'] / (price['Adj Close'].shift(1)))\n",
    "    price.dropna(axis = 0, inplace = True)#第一筆是Nan\n",
    "    \n",
    "    \n",
    "    '''計算Volatility'''\n",
    "    price[\"Volatility\"] = ((np.log(price[\"High\"]) - np.log(price[\"Close\"])) * \\\n",
    "                       (np.log(price[\"High\"]) - np.log(price[\"Open\"]))) + \\\n",
    "                      ((np.log(price[\"Low\"]) - np.log(price[\"Close\"])) * \\\n",
    "                       (np.log(price[\"Low\"]) - np.log(price[\"Open\"])))\n",
    "    \n",
    "    \n",
    "    '''計算Spread'''\n",
    "    a = np.log(price[\"Low\"]) - ( (np.log(price[\"Low\"])+np.log(price[\"High\"]))/2 )\n",
    "    b = np.log(price[\"Low\"]) - ( (np.log(price[\"Low\"].shift(-1))+np.log(price[\"High\"].shift(-1)))/2 )\n",
    "    s = (4*(a*b))\n",
    "    s = s.apply(lambda X: max(X, 0))\n",
    "    price[\"Spread\"] = s ** (1/2)\n",
    "    \n",
    "    \n",
    "    '''clean Price :抓出2017-2020的資料'''\n",
    "    price = price[[\"Date\", \"Return\", \"Adjusted_Return\", \"Volatility\", \"Spread\", \"Volume\"]]#要保留的column\n",
    "    try:\n",
    "        index_start = np.where( price[\"Date\"].apply(lambda X: \"2017\" in X) )[0][0]#2017的第一個\n",
    "        index_end = np.where( price[\"Date\"].apply(lambda X: \"2021\" in X) )[0][0]#2021的第一個\n",
    "        price = price[index_start-5 : index_end]#lag 5，往前推5天\n",
    "    except:#有些股價2017年後才有，所以index_start抓不到東西，直接從0開始\n",
    "        index_end = np.where( price[\"Date\"].apply(lambda X: \"2021\" in X) )[0][0]\n",
    "        price = price[ : index_end]\n",
    "    price.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    '''計算Volume'''\n",
    "    #成交量的平均數為期間內，所以要先抓出需要的期間，才能計算\n",
    "    price[\"Volume\"] = (price[\"Volume\"]-price[\"Volume\"].mean())/price[\"Volume\"].mean()\n",
    "    \n",
    "    \n",
    "    '''計算Size'''\n",
    "    market_cap[\"Size\"] = np.log(market_cap[\"Market_Cap\"] / 1000000)#轉成百萬單位\n",
    "    market_cap.drop([\"Market_Cap\"], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    '''合併Control Variable'''\n",
    "    #依照左邊的DataFrame的Date進行合併 (如果右邊的Date有，但左邊沒有，就不加入)\n",
    "    control = pd.merge(left = price, right = market_cap, how='left', on='Date')\n",
    "    control.dropna(inplace = True)\n",
    "    control.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    '''合併News Variable & Control Variable'''\n",
    "    df = pd.merge(left = control, right = data, how='left', on='Date')\n",
    "       \n",
    "    \n",
    "    '''產生Variable的lag1 ~ lag5'''\n",
    "    #產生新的lag1-lag5之column名\n",
    "    new_column = df.columns.tolist()\n",
    "    for j in range(1,6):\n",
    "        for i in df.columns[1:]:\n",
    "            new_column.append(i + \"_lag\" + str(j))\n",
    "    \n",
    "    #生成lag1-lag5\n",
    "    df = pd.concat([df, df.iloc[:, 1:].shift(1), df.iloc[:, 1:].shift(2), df.iloc[:, 1:].shift(3),\n",
    "                    df.iloc[:, 1:].shift(4), df.iloc[:, 1:].shift(5)], axis = 1)\n",
    "    df = df.iloc[5:]#刪除前五筆None值(control variable)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df.columns = new_column\n",
    "    \n",
    "    #刪除不需要的column\n",
    "    del_column = df.loc[:, \"Volatility\":\"text_sSubjectivity\"].columns\n",
    "    df.drop(del_column, axis = 1, inplace = True)\n",
    "    \n",
    "    #空值全補0\n",
    "    df.fillna(0, inplace = True)\n",
    "\n",
    "    df.to_csv(path1.replace(\"_e.csv\", \"_reg.csv\"), index = False)\n",
    "    \n",
    "    \n",
    "    '''concate regression data'''\n",
    "    df.insert(loc = 0, column = \"symbol\", value = symbol)#增加一欄公司名稱\n",
    "    reg_df = pd.concat([reg_df, df], axis = 0)\n",
    "    reg_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "\n",
    "reg_df.to_csv(\"reg_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "data = pd.read_csv(\"reg_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['head_sNetural_ratio_lag1', 'head_sNetural_ratio_lag2', 'head_sNetural_ratio_lag3',\n",
    "           'head_sNetural_ratio_lag4', 'head_sNetural_ratio_lag5',\n",
    "           'text_sNetural_ratio_lag1', 'text_sNetural_ratio_lag2', 'text_sNetural_ratio_lag3',\n",
    "           'text_sNetural_ratio_lag4', 'text_sNetural_ratio_lag5'], axis = 1,  inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 抓出要用的control variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = input(\"Y 為 Return -> 1 ； Y 為 Adj_Return -> 0: \") # 1 = Return；0 = Adj_Return\n",
    "orignal = [i.replace(\"_lag1\", \"\") for i in data.iloc[:, 4:10].columns]\n",
    "#column 4-10是控制變數，先刪除變數的滯後名(_lag1)\n",
    "\n",
    "#把沒有要用的Y刪掉\n",
    "if int(flag) == 1: #1 = Return\n",
    "    orignal.remove(\"Adj_Return\")\n",
    "else: #0 = Adj_Return\n",
    "    orignal.remove(\"Return\")\n",
    "\n",
    "control = []\n",
    "for j in orignal:\n",
    "    for i in data.iloc[:, 4:].columns:#第四欄開始是控制變數\n",
    "        if int(flag) != 1:\n",
    "            if j in i:#ex: \"Return\" in \"Return_lag2\"\n",
    "                control.append(i)\n",
    "        else:\n",
    "            if (j in i) & (\"Adj_Return\" not in i):#直接用Return下去找會找到Adj_Return，要先設條件\n",
    "                control.append(i)\n",
    "            \n",
    "control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 15, 4):\n",
    "    \n",
    "    Y = data[orignal[0]]\n",
    "    \n",
    "    x = list(data.columns)\n",
    "    X1 =  data[[x[i]] + control]\n",
    "    X2 =  data[[x[i + 1]] + control]\n",
    "    X3 =  data[[x[i + 2]] + control]\n",
    "    X4 =  data[[x[i + 3]] + control]\n",
    "    \n",
    "    results1 = sm.OLS(Y, sm.add_constant(X1)).fit()\n",
    "    results2 = sm.OLS(Y, sm.add_constant(X2)).fit()\n",
    "    results3 = sm.OLS(Y, sm.add_constant(X3)).fit()\n",
    "    results4 = sm.OLS(Y, sm.add_constant(X4)).fit()\n",
    "\n",
    "    df = summary_col([results1, results2, results3, results4], stars = True,\n",
    "                     model_names = [\"Positive\", \"Negative\", \"Polarity\", \"Subjectivity\"],\n",
    "                     regressor_order=[\"const\"] + list(x[i: i+4]) + control)\n",
    "    df = pd.DataFrame(df.tables[0])\n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if (j % 2) == 1:\n",
    "            df.iloc[j, 0] = df.iloc[j, 0] + \"^\"\n",
    "            df.iloc[j, 1] = df.iloc[j, 1] + \"^\"\n",
    "            df.iloc[j, 2] = df.iloc[j, 2] + \"^\"\n",
    "            df.iloc[j, 3] = df.iloc[j, 3] + \"^\"\n",
    "    \n",
    "    if i == 10:\n",
    "        path = \"table/head_lag1.csv\"\n",
    "    else:\n",
    "        path = \"table/text_lag1.csv\"\n",
    "        \n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓出要用的news variable\n",
    "orignal_news = [i.replace(\"_lag1\", \"\") for i in data.iloc[:, 10:20].columns]\n",
    "\n",
    "news = []\n",
    "for j in orignal_news:\n",
    "    for i in data.iloc[:, 8:].columns:\n",
    "        if j in i:\n",
    "            news.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 21, 20):#news variable\n",
    "    \n",
    "    Y = data[orignal[0]]\n",
    "\n",
    "    X1 =  data[news[i:i+5] + control]\n",
    "    X2 =  data[news[i+5:i+10] + control]\n",
    "    X3 =  data[news[i+10:i+15] + control]\n",
    "    X4 =  data[news[i+15:i+20] + control]\n",
    "\n",
    "    results1 = sm.OLS(Y, sm.add_constant(X1)).fit()\n",
    "    results2 = sm.OLS(Y, sm.add_constant(X2)).fit()\n",
    "    results3 = sm.OLS(Y, sm.add_constant(X3)).fit()\n",
    "    results4 = sm.OLS(Y, sm.add_constant(X4)).fit()\n",
    "\n",
    "    df = summary_col([results1, results2, results3, results4], stars = True,\n",
    "                     model_names = [\"Positive\", \"Negative\", \"Polarity\", \"Subjectivity\"],                     \n",
    "                     regressor_order=[\"const\"] + list(news[i:i+21]) + control)\n",
    "    df = pd.DataFrame(df.tables[0])\n",
    "    \n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if (j % 2) == 1:\n",
    "            df.iloc[j, 0] = df.iloc[j, 0] + \"^\"\n",
    "            df.iloc[j, 1] = df.iloc[j, 1] + \"^\"\n",
    "            df.iloc[j, 2] = df.iloc[j, 2] + \"^\"\n",
    "            df.iloc[j, 3] = df.iloc[j, 3] + \"^\"\n",
    "    \n",
    "    if i == 0:\n",
    "        path = \"table/head_lag1-5.csv\"\n",
    "    else:\n",
    "        path = \"table/text_lag1-5.csv\"\n",
    "        \n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covid-19 compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Date\"] = data[\"Date\"].apply(lambda X: datetime.strptime(X, \"%Y-%m-%d\").date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "before_covid = data[datetime.date(2019,12,1) >= data[\"Date\"]]\n",
    "after_covid = data[datetime.date(2019,12,1) <= data[\"Date\"]]\n",
    "\n",
    "before_covid.reset_index(drop = True, inplace = True)\n",
    "after_covid.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in before_covid.iloc[:, 10:18].columns:#news variable\n",
    "    \n",
    "    Y_before = before_covid[orignal[0]]\n",
    "    X_before =  before_covid[[i] + control]\n",
    "    \n",
    "    Y_after = after_covid[orignal[0]]\n",
    "    X_after =  after_covid[[i] + control]\n",
    "    \n",
    "    \n",
    "    results1 = sm.OLS(Y_before, sm.add_constant(X_before)).fit()\n",
    "    results2 = sm.OLS(Y_after, sm.add_constant(X_after)).fit()\n",
    "    \n",
    "\n",
    "    df = summary_col([results1, results2], model_names=[\"Before COVID-19\", \"During COVID-19\"], stars = True)\n",
    "    df = pd.DataFrame(df.tables[0])\n",
    "    \n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if (j % 2) == 1:\n",
    "            df.iloc[j, 0] = df.iloc[j, 0] + \"^\"\n",
    "            df.iloc[j, 1] = df.iloc[j, 1] + \"^\"\n",
    "    \n",
    "    \n",
    "    path = \"table/covid_\" + i.replace(\"_lag1\", \"\") + \".csv\"\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
